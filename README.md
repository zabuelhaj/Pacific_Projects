# Pacific_Projects
A culmination of my work (Independent and with teams) at University of the Pacific; from Undergraduate to Graduate.

### [Microcontrollers](https://github.com/zabuelhaj/Pacific_Projects/tree/master/MP3_Full_Code) ###  
This is an MP3 player that I worked on throughout my Fall 2017 semester. It was developed in C with one portion developed in ARM/Thumb-2 Assembly; the entire project was developed with direct-register manipulation.

### [Embedded Systems](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Embedded_Systems) ###  
These are a handful of projects I completed in my Embedded Systems course during Spring 2018. All of the projects were completed in C, with a couple being conceptual (thus they were not developed on a microcontroller).  

[Real-Time Shortest Job First](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Embedded_Systems/Final_Project)  
This was my team's final project for the course. It is a real-time scheduler that takes push-button inputs from a user to add processes to a queue. When a process is added, the queue adjusts to prioritize processes. The final project was completed using the TivaWare API library.  
[Traffic Scheduler](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Embedded_Systems/Traffic_Scheduling)  
This project was to implement scheduling for traffic lights at an intersection. It uses push-button input to add an ambulance, in which case the lights will change to control traffic and give the ambulance's lane a green light. It was completed using direct-register manipulation.  
[Scheduling Concepts](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Embedded_Systems/Concepts_Scheduling)  
These two projects were completed to test concepts learned in class. One is the classic Hungry Philosophers problem; the other is a simple Queue implementation.

### [Autonomous Robotics](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics) ###  
Because I completed both the Bachelor's and Master's programs at Pacific, I had the opportunity to enroll in both graduate and undergraduate robotics courses. These both focused on autonomous robotic systems, with the "brains" being a Raspberry Pi and TM4C Microcontroller.  

[Basic Implementations](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Undergraduate_Projects)  
The source code found here is from the undergraduate course. I worked with a teammate throughout the semester, using Python on the Raspberry Pi and C on the microcontroller. The microcontroller code was developed with the TivaWare API.  

There are four directories here: [Base_Code](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Undergraduate_Projects/Base_Code) is, well... The base code that was developed throughout the semester. The other three directories are additional files or modifications made to the base code to complete different tasks. An example being [Potential_Fields](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Undergraduate_Projects/Potential_Fields), which contains a Matlab simulation I made as well as the Python code developed to implement this algorithm on the robot. [Grid_Map](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Undergraduate_Projects/Grid_Map) is a basic implementation of a single-heuristic grid map. [Final_Competition](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Undergraduate_Projects/Final_Competition) is the modified code used to traverse the robot through a maze; our final was a competition between each group to traverse to the end of a maze.  

[Advanced Implementations](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Graduate_Projects)  
These are some examples of the more advanced, or higher-level, concepts I implemented in graduate robotics. We used the same robot as the undergraduate course, but focused on the Raspberry Pi. This was because the Raspberry Pi was better suited to handle more complex algorithms, such as computer vision integration and mapping + localization. The microcontroller was still present; it just handled the motion control and low-level sensing. The Raspberry Pi code was implemented in Python, using various modules, such as OpenCV and NumPy.  

There are three directories here, I will try to unpack them the best I can:  
[Tracking_Coverage](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Graduate_Projects/Tracking_Coverage) contains a tracking algorithm, the scripts used to prepare the tracking approach, and a FastSLAM module I wrote. For the Tracking approach, my teammate and I decided to go with a Haar Cascade Classifier. There are a couple reasons for this:  
1. Deep Learning would not require any complicated image processing algorithms to be introduced to the code. We could also use a more feature-rich object to track, in which we used a cartoon character.  
2. Since we were using OpenCV, we had access to some Machine Learning modules. Haar Cascade was one of the available options, and we went with it since we could just take some pictures of our object, pre-process them, and wait for the learning process to complete.  

Now to discuss the files: [Haar_Cascade_Scripts](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Graduate_Projects/Tracking_Coverage/Haar_Cascade_Scripts) holds several scripts my teammate and I wrote and utilized to gather positive and negative images for our Haar Cascade Classifier. Rather than take several hundred photos by hand and spend time cropping them, or etc., we utilized these scripts instead. We have a script that splits videos by frames, producing images for us. Another script goes through these images and crops-out our tracking object through an edge-detection algorithm provided by OpenCV. These pre-processed, positive images then went through our classifier with the negative images. Negative images were randomly gathered by a script that pulled them off flckr. [Tracking_Only.py](https://github.com/zabuelhaj/Pacific_Projects/blob/master/Autonomous_Robotics/Graduate_Projects/Tracking_Coverage/Tracking_Only.py) used the knowledge files produced by the Haar Cascade Classifier to have the robot follow our tracking object.  
Unrelated to tracking is [fastSLAM.py](https://github.com/zabuelhaj/Pacific_Projects/blob/master/Autonomous_Robotics/Graduate_Projects/Tracking_Coverage/fastSLAM.py); this is a Python module I implemented myself to be used in our tracking algorithm. I decided that I wanted to tackle a SLAM algorithm for many reasons: fame, glory, the algorithm's efficiency, and because it's a popular algorithm used by robotics companies (TL;DR fame and glory). I wrote this code as a module only, so it could be used regardless of the accompanying tracking algorithm. Essentially, I integrated this module in code very similar to Tracking_Only.py. However, the modified tracking code was not very pretty and not a good representation of my work, so I just have fastSLAM.py here on its own.  

[Multi_Agent](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Graduate_Projects/Multi_Agent) has mine and my teammate's code for a Multi-Agent robot system. This was used for a project that involved every group's robot; the objective was a game of Simon Says. Each robot had to communicate with eachother: one robot would start as Simon, give a command, then pick another robot to be Simon. The other robots had to perform the correct command and wait to see who was the next Simon. If a robot did not respond when selected as Simon or performed the wrong action, they were dropped from the match. Each robot in the Multi-Agent system used a ZigBee/XBee radio for wireless communication. Every group collaborated on a official communication protocol for the robots to use.  

[Final_Competition](https://github.com/zabuelhaj/Pacific_Projects/tree/master/Autonomous_Robotics/Graduate_Projects/Final_Competition) contains the source code I wrote and contributed to for the final project, which was a tournament of Capture-the-Flag. The class was divided into four teams, each one having four robots. The goal was for each group to develop a Multi-Agent system to complete a game of capture the flag. My team had two offensive robots and two defensive robots. Our approach was a decentralized system, allowing each robot to work independently and communicate as-needed. I wrote the code for [commModule.py](https://github.com/zabuelhaj/Pacific_Projects/blob/master/Autonomous_Robotics/Graduate_Projects/Final_Competition/commModule.py) and [grabControl.py](https://github.com/zabuelhaj/Pacific_Projects/blob/master/Autonomous_Robotics/Graduate_Projects/Final_Competition/grabControl.py); these were modules to utilize a Multi-Agent communication system and to control grippers on the offensive robots, respectively. I additionally contributed to [mainOffensive.py](https://github.com/zabuelhaj/Pacific_Projects/blob/master/Autonomous_Robotics/Graduate_Projects/Final_Competition/mainOffense.py), which used my aforementioned code and contained the logic to search for the opposing team's flag.  

After I completed both robotics courses, I went on to do academic research for autonomous robotics using UAVs. You can read a bit about the research [here](https://github.com/zabuelhaj/Academic_Research).  
